<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[James Tunnell]]></title>
  <link href="http://jamestunnell.github.io/atom.xml" rel="self"/>
  <link href="http://jamestunnell.github.io/"/>
  <updated>2014-11-01T11:39:40-07:00</updated>
  <id>http://jamestunnell.github.io/</id>
  <author>
    <name><![CDATA[James Tunnell]]></name>
    <email><![CDATA[jamestunnell@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[More on the Thesis Proposal]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/11/01/more-on-thesis-proposal/"/>
    <updated>2014-11-01T03:46:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/11/01/more-on-thesis-proposal</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve spent some time studying the high-level problem statement outlined in <a href="http://jamestunnell.github.io/blog/2014/06/25/thesis-proposal">my last post</a>), and I&rsquo;ve identified one of the main obstacles to implementing the Next Release Problem (NRP) in actual software project planning.</p>

<!-- more -->


<p>The obstacle stems from estimating the total cost of project requirements. Of course, the total cost will include implementation cost. But it should also include the cost of fixing software defects (bugs) that arise from the implementation. If bug fixing cost is ignored, then the total cost estimate for each requirement is inaccurate. Thus, there is not a sound sound basis for making optimization decisions involving requirement cost.</p>

<p>So, to overcome this obstacle, <a href="https://github.com/jamestunnell/thesis">my thesis work</a> will focus on providing a probabilistic model based of project historical data. The goal of the model is predicting the makeup of expected bugs resulting from any software changes. I&rsquo;m working this quarter to establish a statistical overview of actual project historical data, starting with the <a href="https://www.mongodb.org/">MongoDB</a> project.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Thesis Proposal]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/25/thesis-proposal/"/>
    <updated>2014-06-25T17:12:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/25/thesis-proposal</id>
    <content type="html"><![CDATA[<p>I&rsquo;m writing up my proposal for the work I&rsquo;m planning to do on the Next Release Problem (NRP, see <a href="http://jamestunnell.github.io/blog/2014/06/25/next-release-problem">my previous post</a>) for my thesis. but here is a rough problem statement:</p>

<blockquote><p>For SW release planners to make use of the NRP, they need a process for mapping many raw measurements, taken from a SW project, onto the nicely abstracted space designated by the NRP.</p></blockquote>

<!-- more -->


<p>If all goes well, I&rsquo;ll have the proposal ready to present by Fall quarter.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Next Release Problem]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/25/next-release-problem/"/>
    <updated>2014-06-25T16:00:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/25/next-release-problem</id>
    <content type="html"><![CDATA[<p>I have spent a few months now trying to select a topic for my thesis, and I&rsquo;ve settled on the Next Release Problem (NRP). It&rsquo;s one of several problems being worked on in the area of Search-Based Software Engineering (SBSE). I only recently discovered SBSE while I was looking into the possibility of optimizing software development task assignment, as suggested by my thesis advisor, <a href="http://www.cwu.edu/~janvik/">Dr. John Anvik</a>. Already very energized by a recent stumbling onto Operations Research, I was glad to see it being applied in the area of SW engineering (where improvement is definitely needed).</p>

<!-- more -->


<h3>The Next Release Problem</h3>

<p>In 2001 the Next Release Problem (NRP) was first defined by Bagnall et al<sup><a href="#Cite1">[1]</a></sup>. It addresses the need to select some subset of all the possible software improvements (features, requirements, or what have you) in order to maximize profit, while respecting an upper limit on the amount of effort that can be expended (resources) in development.</p>

<p>Now it might seem the NRP is just like a 0-1 knapsack problem at this point, but there&rsquo;s an additional consideration: profit is only achieved by satisfying a customer. Each customer can have a different profit, and a different list of enhancements that they would like to be implemented in order to be satisfied. This makes the NRP a bit more interesting. And the NRP is definitely NP-Hard, like the 0-1 knapsack optimization problem.</p>

<h4>References</h4>

<ol>
<li><a name="Cite1"/>Bagnall, Anthony J., Victor J. Rayward-Smith, and Ian M. Whittley. &ldquo;The next release problem.&rdquo; Information and software technology 43.14 (2001): 883-890.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Implementing the Genetic Algorithm]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/13/genetic-algorithm/"/>
    <updated>2014-06-13T02:07:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/13/genetic-algorithm</id>
    <content type="html"><![CDATA[<p>Another project at school this quarter required me to implement the <a href="https://en.wikipedia.org/wiki/Genetic_algorithm">genetic algorithm</a> (GA). It was a bit of a fun project, mostly because the GA is a metaheuristic, so its ripe for reuse. In fact, I used the same GA library on three separate problems. The satisfaction of reuse really motivates me to provide improvements to the library.</p>

<h3>The Code</h3>

<p>The code was written in Ruby. There are a few examples included that you can run right away. The README should help get started.</p>

<blockquote><p><a href="https://github.com/jamestunnell/evolve">https://github.com/jamestunnell/evolve</a></p></blockquote>

<!--more-->


<h3>Details</h3>

<p>Some details might be worth mentioning.</p>

<p>Only a simple GA is implemented. There&rsquo;s not facilities for multiple populations (islands), nor local searching (like memetic, annealing, etc.), nor co-evolution.</p>

<p>On the other hand, it&rsquo;s quite easy to use any one of the built-in methods for selection, mutation, and crossover. Methods for mutation and crossover are avaible by just including one of the built-in modules, like <code>UniformMutation</code> or <code>OnepointCrossover</code>. See the examples to get an idea how this is done. The <code>TournamentSelector</code> class will give you an idea of how to implement a selection method.</p>

<h3>Finally</h3>

<p>In the end, it&rsquo;s not terribly full-featured, but it&rsquo;s easy to use and it may prove useful for quick prototyping of an optimization problem.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[My Personality Type]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/10/my-personality-type/"/>
    <updated>2014-06-10T05:13:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/10/my-personality-type</id>
    <content type="html"><![CDATA[<p>A couple weeks ago I was talking to a campus Career Services rep. He suggested I spend a little time thinking about my personality, so I can reach a more authentic way of operating and presenting myself. Because, he said, employers really do value authenticity so they can know how a potential employee is going to fit into their company. Well, I decided to take him up on that suggestion.</p>

<!--more-->


<p>So I finally sat down and took a <a href="https://en.wikipedia.org/wiki/Myers-Briggs_Type_Indicator">Myer-Briggs</a> assessment, offered for free <a href="http://www.personalitypathways.com/type_inventory.html">here</a>. If you&rsquo;re not familiar, there are four parts for the indicator: introvert/extrovert, sensing/intuitive, thinking/feeling, and judging/perceiving.</p>

<p>The results? Well, they were only a tad inconclusive. I&rsquo;m sure about two of the parts; definitely I am introvertive and intuitive. As for and thinking/feeling, I probably end up more on the thinking end but sometimes not. And the last part, judging/perceiving, I go back and forth. So, according to the chart below, I&rsquo;m up in the top-right corner somewhere. Seems about right to me.</p>

<p><a href="https://commons.wikimedia.org/wiki/File:MyersBriggsTypes.png#mediaviewer/File:MyersBriggsTypes.png"><img alt="MyersBriggsTypes.png" src="https://upload.wikimedia.org/wikipedia/commons/1/1f/MyersBriggsTypes.png" height="432" width="768"></a><br>&#8220;<a href="https://commons.wikimedia.org/wiki/File:MyersBriggsTypes.png#mediaviewer/File:MyersBriggsTypes.png">MyersBriggsTypes</a>&#8221; by <a href="//commons.wikimedia.org/wiki/User:JakeBeech" title="User:JakeBeech">Jake Beech</a> - <span class="int-own-work">Own work</span>. Licensed under <a title="Creative Commons Attribution-Share Alike 3.0" href="http://creativecommons.org/licenses/by-sa/3.0">CC BY-SA 3.0</a> via <a href="//commons.wikimedia.org/wiki/">Wikimedia Commons</a>.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Chaotic Neural Network to Solve the TSP]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/09/chaotic-tsp/"/>
    <updated>2014-06-09T17:19:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/09/chaotic-tsp</id>
    <content type="html"><![CDATA[<p>I just finished up work on a school project with my classmate Sami, solving the traveling salesman problem (TSP) using neural networks (NNs). And not just any NN, but a chaotic NN! What? Yes. And it&rsquo;s amazing.</p>

<h3>The Code</h3>

<p>The code was written in Python. Go try it out! It&rsquo;s not hard to run, and the README should help you get started.</p>

<blockquote><p><a href="https://github.com/jamestunnell/chaotic_tsp">https://github.com/jamestunnell/chaotic_tsp</a></p></blockquote>

<!--more-->


<h3>The Short Story</h3>

<p>Hopfield neural networks are being souped up for optimization, by inducing transient chaotic dynamics. That&rsquo;s basically all there is. (see the long story for more details).</p>

<h3>The Long Story</h3>

<p>We followed the approach described by Aihara and Chen<sup><a href="#Cite1">[1]</a></sup>. They start with a Hopfield NN (HNN), which is fitting since it was Hopfield and Tank<sup><a href="#Cite2">[2]</a></sup> who first applied NNs to solve combinatorial optimization problems, using the HNN of course. So, we start with a HNN. What&rsquo;s missing? Well, the HNN is typically used because it <i>avoids</i> chaotic dynamics (assuming   weights are symmetric and self-connection weights are 0).</p>

<p>In fact, a HNN is guaranteed to converge to a stable local minimum. Well, that&rsquo;s a good thing, actually, but how will this help us produce chaotic dynamics? Chen and Aihara simply add some self-feedback (non-zero self-connection weight). Now we get attractors, and hence rich chaotic dynamics. Now we&rsquo;ve got a mechanism to get our NN to explore the state space (exploratory) instead of going straight for the nearest local minima (greedy). That&rsquo;s what we wanted, but of course this throws the guaranteed convergence right out the window. Hmmm&hellip;</p>

<p>Not to worry, the simple trick is to decay the self-feedback amplitude, just like the cooling in simulated annealing. In fact, the authors are calling this <i>chaotic simulated annealing</i> (CSA) because there&rsquo;s no stochastic behavior in a chaotic system. So as the chaos-inducing term decays, the convergent behavior begins to dominate and the system will magically converge to a local minimum (which could also be the global minimum).</p>

<h3>The Long Long Story</h3>

<p>If you really want it, here it is, in a <a href="http://jamestunnell.github.io/files/csa_tsp.pdf">brief report</a> that Sami and I authored. Or, you can watch our <a href="https://docs.google.com/presentation/d/1ku6XDZD6U9FSL7GWifxkkKqHQyTcFlW7hRSuBttI4Kw/pub?start=false&amp;loop=false&amp;delayms=3000">presentation</a> on the same topic.</p>

<h4>References</h4>

<ol>
<li><a name="Cite1"/>Chen, Luonan, and Kazuyuki Aihara. &ldquo;Chaotic simulated annealing by a neural network model with transient chaos.&rdquo; Neural networks 8.6 (1995): 915-930.</li>
<li><a name="Cite2"/>Hopfield, John J., and David W. Tank. &ldquo;“Neural” computation of decisions in optimization problems.&rdquo; Biological cybernetics 52.3 (1985): 141-152.</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Inaugural Post!]]></title>
    <link href="http://jamestunnell.github.io/blog/2014/06/08/inaugural-post/"/>
    <updated>2014-06-08T04:00:00-07:00</updated>
    <id>http://jamestunnell.github.io/blog/2014/06/08/inaugural-post</id>
    <content type="html"><![CDATA[<p>This is the inaugural post! Posts in the future will (probably) be related to whatever I&rsquo;m working on. Please send me a message if you&rsquo;d like to discuss anything I&rsquo;ve posted (really, please do).</p>

<p>In general, my work is not well-defined right now. I&rsquo;m still chugging along in Grad school at the moment. But I&rsquo;m hopeful that I can find practical ways to improve business operations/processes through analysis, modeling, simulation, optimization, etc. You know, all the good tools you might expect from someone well-versed in Operations Research (OR). Well, I&rsquo;m not one like that, but I am pretty competent in Computer Science, and I&rsquo;m developing the OR part&hellip;</p>
]]></content>
  </entry>
  
</feed>
